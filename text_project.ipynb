{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA20001 Deep Learning - Group Project\n",
    "## Text project\n",
    "\n",
    "**Due Thursday, December 13, before 23:59.**\n",
    "\n",
    "The task is to learn to assign the correct labels to news articles.  The corpus contains ~850K articles from Reuters.  The test set is about 10% of the articles. The data is unextracted in XML files.\n",
    "\n",
    "We're only giving you the code for downloading the data, and how to save the final model. The rest you'll have to do yourselves.\n",
    "\n",
    "Some comments and hints particular to the project:\n",
    "\n",
    "- One document may belong to many classes in this problem, i.e., it's a multi-label classification problem. In fact there are documents that don't belong to any class, and you should also be able to handle these correctly. Pay careful attention to how you design the outputs of the network (e.g., what activation to use) and what loss function should be used.\n",
    "- You may use word-embeddings to get better results. For example, you were already using a smaller version of the GloVE  embeddings in exercise 4. Do note that these embeddings take a lot of memory. \n",
    "- In the exercises we used e.g., `torchvision.datasets.MNIST` to handle the loading of the data in suitable batches. Here, you need to handle the dataloading yourself.  The easiest way is probably to create a custom `Dataset`. [See for example here for a tutorial](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.helsinki.fi/u/jgpyykko/reuters.zip to train/reuters.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.datasets.utils import download_url\n",
    "import zipfile\n",
    "\n",
    "train_path = 'train/'\n",
    "\n",
    "dl_file='reuters.zip'\n",
    "dl_url='https://www.cs.helsinki.fi/u/jgpyykko/'\n",
    "zip_path = os.path.join(train_path, dl_file)\n",
    "if not os.path.isfile(zip_path):\n",
    "    download_url(dl_url + dl_file, root=train_path, filename=dl_file, md5=None)\n",
    "\n",
    "with zipfile.ZipFile(zip_path) as zip_f:\n",
    "    zip_f.extractall(train_path)\n",
    "    #os.unlink(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command downloads and extracts the data files into the `train` subdirectory.\n",
    "\n",
    "The files can be found in `train/`, and are named as `19970405.zip`, etc. You will have to manage the content of these zips to get the data. There is a readme which has links to further descriptions on the data.\n",
    "\n",
    "The class labels, or topics, can be found in the readme file called `train/codes.zip`.  The zip contains a file called \"topic_codes.txt\".  This file contains the special codes for the topics (about 130 of them), and the explanation - what each code means.  \n",
    "\n",
    "The XML document files contain the article's headline, the main body text, and the list of topic labels assigned to each article.  You will have to extract the topics of each article from the XML.  For example: \n",
    "&lt;code code=\"C18\"&gt; refers to the topic \"OWNERSHIP CHANGES\" (like a corporate buyout).\n",
    "\n",
    "You should pre-process the XML to extract the words from the article: the &lt;headline&gt; element and the &lt;text&gt;.  You should not need any other parts of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your stuff goes here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "; Topic Codes\n",
    "; CODE  DESCRIPTION\n",
    "1POL    CURRENT NEWS - POLITICS\n",
    "2ECO    CURRENT NEWS - ECONOMICS\n",
    "3SPO    CURRENT NEWS - SPORT\n",
    "4GEN    CURRENT NEWS - GENERAL\n",
    "6INS    CURRENT NEWS - INSURANCE\n",
    "7RSK    CURRENT NEWS - RISK NEWS\n",
    "8YDB    TEMPORARY\n",
    "9BNX    TEMPORARY\n",
    "ADS10   CURRENT NEWS - ADVERTISING\n",
    "BNW14   CURRENT NEWS - BUSINESS NEWS\n",
    "BRP11   CURRENT NEWS - BRANDS\n",
    "C11     STRATEGY/PLANS\n",
    "C12     LEGAL/JUDICIAL\n",
    "C13     REGULATION/POLICY\n",
    "C14     SHARE LISTINGS\n",
    "C15     PERFORMANCE\n",
    "C151    ACCOUNTS/EARNINGS\n",
    "C1511   ANNUAL RESULTS\n",
    "C152    COMMENT/FORECASTS\n",
    "C16     INSOLVENCY/LIQUIDITY\n",
    "C17     FUNDING/CAPITAL\n",
    "C171    SHARE CAPITAL\n",
    "C172    BONDS/DEBT ISSUES\n",
    "C173    LOANS/CREDITS\n",
    "C174    CREDIT RATINGS\n",
    "C18     OWNERSHIP CHANGES\n",
    "C181    MERGERS/ACQUISITIONS\n",
    "C182    ASSET TRANSFERS\n",
    "C183    PRIVATISATIONS\n",
    "C21     PRODUCTION/SERVICES\n",
    "C22     NEW PRODUCTS/SERVICES\n",
    "C23     RESEARCH/DEVELOPMENT\n",
    "C24     CAPACITY/FACILITIES\n",
    "C31     MARKETS/MARKETING\n",
    "C311    DOMESTIC MARKETS\n",
    "C312    EXTERNAL MARKETS\n",
    "C313    MARKET SHARE\n",
    "C32     ADVERTISING/PROMOTION\n",
    "C33     CONTRACTS/ORDERS\n",
    "C331    DEFENCE CONTRACTS\n",
    "C34     MONOPOLIES/COMPETITION\n",
    "C41     MANAGEMENT\n",
    "C411    MANAGEMENT MOVES\n",
    "C42     LABOUR\n",
    "CCAT    CORPORATE/INDUSTRIAL\n",
    "E11     ECONOMIC PERFORMANCE\n",
    "E12     MONETARY/ECONOMIC\n",
    "E121    MONEY SUPPLY\n",
    "E13     INFLATION/PRICES\n",
    "E131    CONSUMER PRICES\n",
    "E132    WHOLESALE PRICES\n",
    "E14     CONSUMER FINANCE\n",
    "E141    PERSONAL INCOME\n",
    "E142    CONSUMER CREDIT\n",
    "E143    RETAIL SALES\n",
    "E21     GOVERNMENT FINANCE\n",
    "E211    EXPENDITURE/REVENUE\n",
    "E212    GOVERNMENT BORROWING\n",
    "E31     OUTPUT/CAPACITY\n",
    "E311    INDUSTRIAL PRODUCTION\n",
    "E312    CAPACITY UTILIZATION\n",
    "E313    INVENTORIES\n",
    "E41     EMPLOYMENT/LABOUR\n",
    "E411    UNEMPLOYMENT\n",
    "E51     TRADE/RESERVES\n",
    "E511    BALANCE OF PAYMENTS\n",
    "E512    MERCHANDISE TRADE\n",
    "E513    RESERVES\n",
    "E61     HOUSING STARTS\n",
    "E71     LEADING INDICATORS\n",
    "ECAT    ECONOMICS\n",
    "ENT12   CURRENT NEWS - ENTERTAINMENT\n",
    "G11     SOCIAL AFFAIRS\n",
    "G111    HEALTH/SAFETY\n",
    "G112    SOCIAL SECURITY\n",
    "G113    EDUCATION/RESEARCH\n",
    "G12     INTERNAL POLITICS\n",
    "G13     INTERNATIONAL RELATIONS\n",
    "G131    DEFENCE\n",
    "G14     ENVIRONMENT\n",
    "G15     EUROPEAN COMMUNITY\n",
    "G151    EC INTERNAL MARKET\n",
    "G152    EC CORPORATE POLICY\n",
    "G153    EC AGRICULTURE POLICY\n",
    "G154    EC MONETARY/ECONOMIC\n",
    "G155    EC INSTITUTIONS\n",
    "G156    EC ENVIRONMENT ISSUES\n",
    "G157    EC COMPETITION/SUBSIDY\n",
    "G158    EC EXTERNAL RELATIONS\n",
    "G159    EC GENERAL\n",
    "GCAT    GOVERNMENT/SOCIAL\n",
    "GCRIM   CRIME, LAW ENFORCEMENT\n",
    "GDEF    DEFENCE\n",
    "GDIP    INTERNATIONAL RELATIONS\n",
    "GDIS    DISASTERS AND ACCIDENTS\n",
    "GEDU    EDUCATION\n",
    "GENT    ARTS, CULTURE, ENTERTAINMENT\n",
    "GENV    ENVIRONMENT AND NATURAL WORLD\n",
    "GFAS    FASHION\n",
    "GHEA    HEALTH\n",
    "GJOB    LABOUR ISSUES\n",
    "GMIL    MILLENNIUM ISSUES\n",
    "GOBIT   OBITUARIES\n",
    "GODD    HUMAN INTEREST\n",
    "GPOL    DOMESTIC POLITICS\n",
    "GPRO    BIOGRAPHIES, PERSONALITIES, PEOPLE\n",
    "GREL    RELIGION\n",
    "GSCI    SCIENCE AND TECHNOLOGY\n",
    "GSPO    SPORTS\n",
    "GTOUR   TRAVEL AND TOURISM\n",
    "GVIO    WAR, CIVIL WAR\n",
    "GVOTE   ELECTIONS\n",
    "GWEA    WEATHER\n",
    "GWELF   WELFARE, SOCIAL SERVICES\n",
    "M11     EQUITY MARKETS\n",
    "M12     BOND MARKETS\n",
    "M13     MONEY MARKETS\n",
    "M131    INTERBANK MARKETS\n",
    "M132    FOREX MARKETS\n",
    "M14     COMMODITY MARKETS\n",
    "M141    SOFT COMMODITIES\n",
    "M142    METALS TRADING\n",
    "M143    ENERGY MARKETS\n",
    "MCAT    MARKETS\n",
    "MEUR    EURO CURRENCY\n",
    "PRB13   CURRENT NEWS - PRESS RELEASE WIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how much data we need per label# Here goes your code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your model\n",
    "\n",
    "It might be useful to save your model if you want to continue your work later, or use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model file should now be visible in the \"Home\" screen of the jupyter notebooks interface.  There you should be able to select it and press \"download\".\n",
    "\n",
    "## Download test set\n",
    "\n",
    "The testset will be made available during the last week before the deadline and can be downloaded in the same way as the training set.\n",
    "\n",
    "## Predict for test set\n",
    "\n",
    "You will be asked to return your predictions a separate test set.  These should be returned as a matrix with one row for each test article.  Each row contains a binary prediction for each label, 1 if it's present in the image, and 0 if not. The order of the labels is the order of the label (topic) codes.\n",
    "\n",
    "An example row could like like this if your system predicts the presense of the second and fourth topic:\n",
    "\n",
    "    0 1 0 1 0 0 0 0 0 0 0 0 0 0 ...\n",
    "    \n",
    "If you have the matrix prepared in `y` you can use the following function to save it to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.txt', y, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
